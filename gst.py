# -*- coding: utf-8 -*-
"""GST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-jk43xa9vhEcW3hvLGIa2gcuVmy7wfBL

AN ML MODEL FOR THE PREDICTING THE BEAST CLASSIFIER FOR THE GIVEN GST DATA
"""

#Importing all the necessary Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,precision_score,recall_score,f1_score,roc_auc_score,ConfusionMatrixDisplay,roc_curve,confusion_matrix

pd.set_option('display.max_columns',None)#Makes sure that there is no restriction on the number of columns to be displayed

#Reading the data from the files
X_Train_Input = pd.read_csv('/content/X_Train_Data_Input.csv')
Y_Train_Data_Target=pd.read_csv('/content/Y_Train_Data_Target.csv')
X_Test_Input=pd.read_csv('/content/X_Test_Data_Input.csv')
Y_Test_Input=pd.read_csv('/content/Y_Test_Data_Target.csv')

"""Checking and removing NAN values Of X_Train

"""

X_Train_Input

X_Train_Input.isna().sum().sum()

missing_vals=["NAN","",None,]
X_Train_missing_values=X_Train_Input.isin(missing_vals)
X_Train_missing_values.head()

X_Train_Input=X_Train_Input.drop('ID',axis=1)

missing_vals=["NAN","",None,"NA"]
X_Train_missing_values=X_Train_Input.isin(missing_vals)
X_Train_mean= X_Train_Input.mean()
X_Train_Input=X_Train_Input.mask(X_Train_missing_values, X_Train_mean,axis=1)

X_Train_Input

X_Train_Input.isna().sum().sum()

"""Checking and removing the NAN values of Y_Train

"""

Y_Train_Data_Target

Y_Train_Data_Target=Y_Train_Data_Target.drop("ID",axis=1)

Y_Train_Data_Target.isna().sum()

"""Checking and removing NAN values of X_Test"""

X_Test_Input

X_Test_Input.isna().sum().sum()

X_Test_Input=X_Test_Input.drop('ID',axis=1)

missing_values=["NAN",'',None]
X_Test_missingvalues=X_Test_Input.isin(missing_values)
X_Test_Mean=X_Test_Input.mean()
X_Test_Input=X_Test_Input.mask(X_Test_missingvalues, X_Test_Mean,axis=1)

X_Test_Input.isna().sum().sum()

"""Y_Test checking and removing NA values"""

Y_Test_Input

Y_Test_Input=Y_Test_Input.drop("ID",axis=1)

Y_Test_Input.isna().sum()

"""

Normalization
"""

#Normalizing the data using StandardScaler to make sure the data is in between 0-1

from sklearn.preprocessing import StandardScaler
sv=StandardScaler()

x_test_scaled=sv.fit_transform(X_Test_Input)
x_test_scaled=pd.DataFrame(x_test_scaled)

x_train_scaled=sv.fit_transform(X_Train_Input)
x_train_scaled=pd.DataFrame(x_train_scaled)

"""Training and testing the data"""

X_Train, X_Test, Y_Train, Y_Test = train_test_split(x_test_scaled, Y_Test_Input, test_size=0.2, random_state=42)

#ravel() is used to covert the Y data into 1D array from 2D array
#Why? == The classifier expects only 1D array
Y_Train=Y_Train.values.ravel()
Y_Test=Y_Test.values.ravel()

#To make sure there are no extra data
print(Y_Train.shape)
print(X_Train.shape)

"""Calcuating the Accuracy for Classifiers"""

#Takes time(8-10 mins) to read and predict the model
models={
    "Support Vector Classifier":SVC(),
    "Gaussian NB":GaussianNB(),
    "clf":DecisionTreeClassifier(),
    "Logestic Regression":LogisticRegression()
}
for i in range(len(list(models))):
  model=list(models.values())[i]
  model.fit(X_Train,Y_Train)

  y_train_pred=model.predict(X_Train)
  y_test_pred=model.predict(X_Test)

  model_train_accuracy = accuracy_score(Y_Train,y_train_pred)
  model_train_f1= f1_score(Y_Train,y_train_pred,average='weighted')
  model_train_precision=precision_score(Y_Train,y_train_pred)
  model_train_recall=recall_score(Y_Train,y_train_pred)
  model_train_rocauc_score= roc_auc_score(Y_Train,y_train_pred)

  model_test_accuracy=accuracy_score(Y_Test,y_test_pred)
  model_test_f1=f1_score(Y_Test,y_test_pred,average='weighted')
  model_test_precision=precision_score(Y_Test,y_test_pred)
  model_test_recall=recall_score(Y_Test,y_test_pred)
  model_test_rocauc_score=roc_auc_score(Y_Test,y_test_pred)

  print(list(models.keys())[i])

  print("Model Performance For Training set")
  print("- Accuracy Score : {:.4f}".format(model_train_accuracy*100))
  print("-F1 Score: {:.4f}".format(model_train_f1*100))
  print("-Precision: {:.4f}".format(model_train_precision*100))
  print('-Recall: {:.4f}'.format(model_train_recall*100))
  print('-Roc Auc Score: {:.4f}'.format(model_train_rocauc_score*100))

  print('--------------------------------------------------------------')

  print('Model Performance For Test Set')
  print('-Accuracy: {:.4f}'.format(model_test_accuracy*100))
  print('-F1 Score: {:.4f}'.format(model_test_f1*100))
  print('-Precision: {:.4f}'.format(model_test_precision*100))
  print('-Recall: {:.4f}'.format(model_test_recall*100))
  print('-Roc Auc Score: {:.4f}'.format(model_test_rocauc_score*100))



  # Confusion Matrix
  cm = confusion_matrix(Y_Test, y_test_pred)
  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
  disp.plot(cmap='Blues')
  plt.title(f'Confusion Matrix for {list(models.keys())[i]}')
  plt.show()
  print('='*35)
  print('\n')

"""ANN Classifier"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as k
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Input

#Building the model in  a sequentail manner(Layer by Layer)
model = Sequential()
model.add(Input(shape=(22,)))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(3, activation='softmax'))

y_pred = (y_test_pred > 0.5).astype(int)

# Compiling the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#Model fitting takes around 10 mins
model.fit(X_Train, Y_Train, epochs=150, batch_size=150, verbose=0)

# Evaluate the model
loss, accuracy= model.evaluate(X_Test, Y_Test, verbose=0)

print(f'Accuracy: {accuracy * 100:.4f}')

precision = precision_score(Y_Test, y_pred)
recall = recall_score(Y_Test, y_pred)
f1 = f1_score(Y_Test, y_pred)
roc= roc_auc_score(Y_Test,y_pred)

print(f'Precision: {precision *100:.4f}')
print(f'Recall: {recall *100:.4f}')
print(f'F1 Score: {f1 *100:.4f}')
print(f'ROC_AUC_SCORE: {roc*100:.4f}')
 # Confusion Matrix
cm = confusion_matrix(Y_Test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title(f'Confusion Matrix for Artificial Neural Network')
plt.show()

print("The Best Classifier for the GST dataset is Support Vector Classifier with accuracy:97%")